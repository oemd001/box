{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# the code below assumes that you configure boto3 with your AWS account\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n",
    "ec2 = boto3.resource('ec2')\n",
    "client = boto3.client('ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Your_name\"\n",
    "# ^-- must be unique per experiment\n",
    "\n",
    "\n",
    "coordinator_type = \"r5.large\"\n",
    "dht_port = 31337\n",
    "worker_type = \"g4dn.2xlarge\"\n",
    "num_workers = 16 ## number of GPU instances in your experiment\n",
    "num_aux = 4 ## number of auxiliary CPU instances (maybe zero)\n",
    "\n",
    "bands = [{\"up\":200,\"down\":200}]*4+[{\"up\":100,\"down\":100}]*8+[{\"up\":50,\"down\":50}]*4  ## bandwidth of GPU peers, mbps\n",
    "\n",
    "image_id = \"ami-0db67995cd75f5a9f\"\n",
    "aws_key_name = \"aws\"  ## update with your aws key name\n",
    "subnet = \"\"  ## update with your subnet name or skip entirely\n",
    "security_group = \"\"  ## you guessed it\n",
    "data_path = \"\" ## path to an archive with wikitext103 dataset\n",
    "repo_path = \"\" ## path to the repo with code of our `src` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the experiment name is unique.\n",
    "# disable this if you want to add more instances to an existing experiment\n",
    "existing_instances = ec2.instances.filter(Filters=[\n",
    "    {'Name': 'instance-state-name', 'Values': ['running']},\n",
    "    {'Name': 'tag:experiment', 'Values': [experiment_name]},\n",
    "])\n",
    "ins = list(existing_instances)\n",
    "if ins:\n",
    "    print(f\"Already running {experiment_name}: {ins}\")\n",
    "    print(len(ins))\n",
    "    for i in ins:\n",
    "        print(i.public_ip_address, i.private_ip_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to remove all instances and spot requests, uncomment and run this:\n",
    "# existing_instances.terminate()\n",
    "# requests_to_shutdown = []\n",
    "# for request in client.describe_spot_instance_requests()['SpotInstanceRequests']:\n",
    "#     if request['State'] == 'active' and any(\n",
    "#         tag['Key'] == 'experiment' and tag['Value'] == experiment_name\n",
    "#         for tag in request['Tags']):\n",
    "#         requests_to_shutdown.append(request['SpotInstanceRequestId'])\n",
    "# if requests_to_shutdown:\n",
    "#     client.cancel_spot_instance_requests(\n",
    "#         SpotInstanceRequestIds=requests_to_shutdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: run coordinator\n",
    "\n",
    "Coordinator is an instance that welcomes new peers into a decentralized training run. If coordinator is down, new peers can still join by initializing with one of the existing peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WandB_API_key = \"\"  ## Your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator_script = f'''#!/bin/bash -ex\n",
    "exec > >(tee /var/log/user-command.log|logger -t user-data -s 2>/dev/console) 2>&1\n",
    "\n",
    "\n",
    "\n",
    "git clone {repo_path}\n",
    "cd DeDLOC\n",
    "\n",
    "pip install -e ./src\n",
    "cd albert\n",
    "\n",
    "\n",
    "ulimit -n 4096\n",
    "\n",
    "\n",
    "sh -c 'cat <<\"EOF\" >> ~/.netrc\n",
    "machine api.wandb.ai\n",
    "  login user\n",
    "  password {WandB_API_key}\n",
    "EOF'\n",
    "\n",
    "HIVEMIND_THREADS=128 python ./run_first_peer.py --dht_listen_on [::]:{dht_port} \\\n",
    " --experiment_prefix {experiment_name} --wandb_project Runs \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coordinator, = ec2.create_instances(\n",
    "    ImageId=image_id, InstanceType=coordinator_type,\n",
    "    MinCount=1, MaxCount=1,\n",
    "    SecurityGroupIds=[security_group], SubnetId=subnet,\n",
    "    KeyName=aws_key_name, UserData=coordinator_script,\n",
    "    TagSpecifications=[{'ResourceType': 'instance', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'first_peer'}\n",
    "    ]}]\n",
    ")\n",
    "coordinator.wait_until_running()\n",
    "coordinator, = list(ec2.instances.filter(InstanceIds=[coordinator.id]))\n",
    "\n",
    "\n",
    "coordinator_ip = coordinator.public_ip_address\n",
    "\n",
    "coordinator_endpoint = f\"{coordinator_ip}:{dht_port}\"\n",
    "print(coordinator_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1.5: run auxiliary CPU peers\n",
    "\n",
    "Auxiliary peers are CPU instances that take gradients from workers and perform averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_script = f'''#!/bin/bash -ex\n",
    "exec > >(tee /var/log/user-command.log|logger -t user-data -s 2>/dev/console) 2>&1\n",
    "\n",
    "\n",
    "\n",
    "sudo yum install tc -y\n",
    "\n",
    "\n",
    "git clone https://github.com/magnific0/wondershaper.git\n",
    "cd wondershaper\n",
    "sudo ./wondershaper -a eth0 -u {500*1024} -d {500*1024}\n",
    "cd ..\n",
    "\n",
    "\n",
    "\n",
    "git clone {repo_path}\n",
    "cd DeDLOC\n",
    "\n",
    "pip install -e ./src\n",
    "cd albert\n",
    "\n",
    "\n",
    "mkdir -p ~/data\n",
    "wget -qO- {data_path} | tar xzf -\n",
    "\n",
    "\n",
    "\n",
    "ulimit -n 4096\n",
    "\n",
    "\n",
    "sh -c 'cat <<\"EOF\" >> ~/.netrc\n",
    "machine api.wandb.ai\n",
    "  login user\n",
    "  password {WandB_API_key}\n",
    "EOF'\n",
    "\n",
    "\n",
    "WANDB_PROJECT={experiment_name} HIVEMIND_THREADS=128 python run_aux.py \\\n",
    "  --output_dir ./outputs --overwrite_output_dir \\\n",
    "  --logging_dir ./logs --logging_first_step --logging_steps 100 \\\n",
    "  --initial_peers {coordinator_endpoint} \\\n",
    "  --experiment_prefix {experiment_name} --seed 42 --averaging_timeout 120 --fp16 False --bandwidth 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_aux):\n",
    "    aux, = ec2.create_instances(\n",
    "        ImageId=image_id, InstanceType=coordinator_type,\n",
    "        MinCount=1, MaxCount=1,\n",
    "        SecurityGroupIds=[security_group], SubnetId=subnet,\n",
    "        KeyName=aws_key_name, UserData=aux_script,\n",
    "        TagSpecifications=[{'ResourceType': 'instance', 'Tags': [\n",
    "            {'Key':'experiment', 'Value': experiment_name},\n",
    "            {'Key':'role', 'Value': 'aux_peer'}\n",
    "        ]}]\n",
    "    )\n",
    "    aux.wait_until_running()\n",
    "    aux, = list(ec2.instances.filter(InstanceIds=[aux.id]))\n",
    "\n",
    "    print(aux.private_ip_address, aux.public_ip_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: run workers\n",
    "\n",
    "Workers are preemptible GPU instances that run compute gradients and perform averaging. In this example, each worker is a single tesla T4 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_w(params):\n",
    "    worker_script = f'''#!/bin/bash -ex\n",
    "exec > >(tee /var/log/user-command.log|logger -t user-data -s 2>/dev/console) 2>&1\n",
    "\n",
    "\n",
    "sudo yum install tc -y\n",
    "\n",
    "\n",
    "git clone https://github.com/magnific0/wondershaper.git\n",
    "cd wondershaper\n",
    "sudo ./wondershaper -a eth0 -u {params[\"up\"]*1024} -d {params[\"down\"]*1024}\n",
    "cd ..\n",
    "\n",
    "\n",
    "git clone {repo_path}\n",
    "cd DeDLOC\n",
    "\n",
    "pip install -e ./src\n",
    "cd albert\n",
    "\n",
    "\n",
    "mkdir -p ~/data\n",
    "wget -qO- {data_path} | tar xzf -\n",
    "\n",
    "\n",
    "sh -c 'cat <<\"EOF\" >> ~/.netrc\n",
    "machine api.wandb.ai\n",
    "  login user\n",
    "  password {WandB_API_key}\n",
    "EOF'\n",
    "\n",
    "\n",
    "ulimit -n 4096\n",
    "\n",
    "WANDB_PROJECT={experiment_name} HIVEMIND_THREADS=128 python run_trainer.py \\\n",
    "  --output_dir ./outputs --overwrite_output_dir \\\n",
    "  --logging_dir ./logs --logging_first_step --logging_steps 100 \\\n",
    "  --initial_peers {coordinator_endpoint} --run_name aws_worker \\\n",
    "  --experiment_prefix {experiment_name} --seed 42 --client_mode False --averaging_timeout 120  --bandwidth {params[\"up\"]}\n",
    "'''\n",
    "    return worker_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance(worker_type, i):\n",
    "    new_worker, = ec2.create_instances(\n",
    "    ImageId=image_id, InstanceType=worker_type,\n",
    "    MinCount=1, MaxCount=1,\n",
    "    UserData=gen_w(s[i]),\n",
    "    SecurityGroupIds=[security_group], SubnetId=subnet, \n",
    "    KeyName=aws_key_name,\n",
    "    InstanceMarketOptions={\n",
    "        \"MarketType\": \"spot\",\n",
    "        \"SpotOptions\": {\n",
    "            \"SpotInstanceType\": \"one-time\",\n",
    "            \"InstanceInterruptionBehavior\": \"terminate\"\n",
    "        }\n",
    "    },\n",
    "    TagSpecifications=[{'ResourceType': 'instance', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'gpu_worker'},\n",
    "        {'Key':'type', 'Value': str(i)}\n",
    "    ]}, {'ResourceType': 'spot-instances-request', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'gpu_worker'}\n",
    "    ]}],)\n",
    "    return new_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    existing_instances = list(ec2.instances.filter(Filters=[\n",
    "        {'Name': 'instance-state-name', 'Values': ['running']},\n",
    "        {'Name': 'tag:experiment', 'Values': [experiment_name]},\n",
    "    ]))\n",
    "    count_needed = num_workers + 1 - len(existing_instances)\n",
    "    if count_needed > 0:\n",
    "        for i in range(num_workers):\n",
    "            for ins in existing_instances:\n",
    "                for tag in ins.tags:\n",
    "                    if tag[\"Value\"] == str(i):\n",
    "                        break\n",
    "        try:\n",
    "            worker_type = \"g4dn.xlarge\"\n",
    "            print(f\"Need {count_needed} more workers. Trying to spawn one\")\n",
    "            new_worker = create_instance(worker_type, i)\n",
    "            new_worker.wait_until_running()\n",
    "            new_worker, = list(ec2.instances.filter(InstanceIds=[new_worker.id]))\n",
    "            print(\"CREATED ONE WORKER!\", worker_type, \n",
    "                  new_worker.public_ip_address, new_worker.private_ip_address)\n",
    "        except BaseException as e:\n",
    "            try:\n",
    "                worker_type = \"g4dn.2xlarge\"\n",
    "                new_worker = create_instance(worker_type, i)\n",
    "                new_worker.wait_until_running()\n",
    "                new_worker, = list(ec2.instances.filter(InstanceIds=[new_worker.id]))\n",
    "                print(\"CREATED ONE WORKER!\", worker_type, \n",
    "                      new_worker.public_ip_address, new_worker.private_ip_address)\n",
    "            except BaseException as e:\n",
    "                print(\"FAILED\", e)\n",
    "    else:\n",
    "        print(\"Enough workers already, check back in 60s...\")\n",
    "        time.sleep(60)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
